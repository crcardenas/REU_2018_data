{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis Pipeline\n",
    "This pipeline is modeled after:\n",
    "1. [Carol Rowe's Allenrolfea analysis](https://digitalcommons.usu.edu/all_datasets/39/)\n",
    "2. [emprical ipyrad API pedicularis](https://nbviewer.jupyter.org/github/dereneaton/ipyrad/blob/master/tests/cookbook-empirical-API-1-pedicularis.ipynb)\n",
    "3. see Grundwald Lab [Poppr analysis](http://grunwaldlab.github.io/Population_Genetics_in_R/index.html) tutorial on github\n",
    "<br>\n",
    "<br>\n",
    "*to be updated with further population analysis as well* <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#required modules/programs/packages\n",
    "#seaborn\n",
    "#pandas\n",
    "#numpy\n",
    "#ipyparallel\n",
    "#ipyrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check `ipcluster` instance with a profile**<br>\n",
    "First we need to check our paralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipyparallel version is 6.0.2\n",
      "mpi1 has 15 cores\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "print 'ipyparallel version is', ipp.__version__\n",
    "mpi1 = ipp.Client(profile=\"MPI1\")\n",
    "print 'mpi1 has',len(mpi1), 'cores'\n",
    "mpi1.ids #this has the same effect as `len(mpi1)`; \n",
    "#take note python counting starts at zero!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *ipyrad*\n",
    "The only library we need to import is *ipyrad*. The import command is usually the first code called in a Python document to load any necessary packages. In the code below, we use a convenient trick in Python to tell it that we want to refer to ipyrad simply as ip. This saves us a little space since we might type the name many times. Below that, we use the print statement to print the version number of *ipyrad*. This is good practice to keep a record of which software version we are using. <br>\n",
    "<br>\n",
    "This guide and markdown is straight from the [*ipyrad* API user guide](https://ipyrad.readthedocs.io/API_user-guide.html) but will be using 2019_thesis data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.28\n"
     ]
    }
   ],
   "source": [
    "#requires ipyrad\n",
    "import ipyrad as ip\n",
    "print ip.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structure\n",
    "There are two main objects in *ipyrad*: Assembly class objects and Sample class objects. And in fact, most users will only ever interact with the Assembly class objects, since Sample objects are stored inside of the Assembly objects, and the Assembly objects have functions, such as merge, and branch, that are designed for manipulating and exchanging Samples between different Assemblies. <br>\n",
    "### Assembly class objects\n",
    "Assembly objects are a unique data structure that ipyrad uses to store and organize information about how to Assemble RAD-seq data. It contains functions that can be applied to data, such as clustering, and aligning sequences. And it stores information about which settings (prarmeters) to use for assembly functions, and which Samples the functions should be applied to. You can think of it mostly as a container that has a set of rules associated with it. <br>\n",
    "To create a new Assembly object use the `ip.Assembly()` function and pass it the name of your new Assembly. Creating an object in this way has exactly the same effect as using the **-n {name}** argument in the *ipyrad* command line tool, except in the API instead of creating a params.txt file, we store the new Assembly information in a Python variable. This can be named anything you want. Below I name the variable *data1* so it is easy to remember that the Assembly name is also data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Assembly: data1\n"
     ]
    }
   ],
   "source": [
    "data1 = ip.Assembly(\"data1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters\n",
    "You now have a Assembly object with a default set of parameters associated with it, analogous to the params file in the command line tool. You can view and modify these parameters using two arguments to the Assembly object, `set_params()` and `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IPyradError",
     "evalue": "    Error setting parameter 'raw_fastq_path'\n        The value entered for the path to the raw fastq file is unrecognized.\n    Please be sure this path is correct. Double check the file name and\n    the file extension. If it is a relative path be sure the path is\n    correct with respect to the directory you're running ipyrad from.\n    You entered: /home/cardenas.61/output/cluster_analysis/both_outfiles/*.gz\n\n    You entered: ./*.gz\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIPyradError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d11154b68050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## set and modify params for this assembly object here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'project_dir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this will need to be run for EACH assembly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw_fastq_path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./*.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'barcodes_path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gonna need to fix this, remember there was an issue with what Restriction codes gave us!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'assembly_method'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'denovo+refrence'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cardenas.61/.conda/envs/local/lib/python2.7/site-packages/ipyrad/core/assembly.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, param, newvalue)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             raise IPyradWarningExit(BAD_PARAMETER\\\n\u001b[0;32m--> 815\u001b[0;31m                                     .format(param, inst, newvalue))\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cardenas.61/.conda/envs/local/lib/python2.7/site-packages/ipyrad/assemble/util.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mipyrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__interactive__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIPyradError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mSystemExit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIPyradError\u001b[0m:     Error setting parameter 'raw_fastq_path'\n        The value entered for the path to the raw fastq file is unrecognized.\n    Please be sure this path is correct. Double check the file name and\n    the file extension. If it is a relative path be sure the path is\n    correct with respect to the directory you're running ipyrad from.\n    You entered: /home/cardenas.61/output/cluster_analysis/both_outfiles/*.gz\n\n    You entered: ./*.gz\n    "
     ]
    }
   ],
   "source": [
    "## set and modify params for this assembly object here\n",
    "data1.set_params('project_dir', './') # this will need to be run for EACH assembly\n",
    "data1.set_params('raw_fastq_path', './*.gz') # your file\n",
    "data1.set_params('barcodes_path', '') # gonna need to fix this, remember there was an issue with what Restriction codes gave us!\n",
    "data1.set_params('assembly_method', 'denovo+refrence') #denovo+refrence seemed to work well.\n",
    "data1.set_params('refrence_sequence', 'Tzet_genomic.fna')\n",
    "data1.set_params('datatype', 'ddrad')\n",
    "data1.set_params('restriction_overhang', 'TGCAG, CGG') # remember there was an issue with what Restriction codes gave us!\n",
    "data1.set_params('mindepth_statistical', '6')\n",
    "data1.set_params('mindepth_majrule', '6')\n",
    "data1.set_params('filter_adapters', '1')# do two runsrun with 1 and one with 2 (2= stricter)\n",
    "data1.set_params('max_SNPs_locus', '20, 30') # 20,20 is standard in ipyrad, we used 20,30 last time\n",
    "# ...\n",
    "\n",
    "#print param file\n",
    "data1.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantaneous parameter (and error) checking\n",
    "A nice feature of the `set_params()` function in the *ipyrad* API is that it checks your parameter settings at the time that you change them to make sure that they are compatible. By contrast, the *ipyrad* CLI does not check params until you try to run a step function. As you saw, we assigned any `./*.gz`file in the directory for the raw_fastq_path parameter, but it doesnt exist in this directory so it throws an error. <br>\n",
    "once you get it all fixed you can print your param file and make sure everything looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   assembly_name               data1                                        \n",
      "1   project_dir                 /home/cardenas.61/output/cluster_analysis/both_outfiles\n",
      "2   raw_fastq_path                                                           \n",
      "3   barcodes_path                                                            \n",
      "4   sorted_fastq_path                                                        \n",
      "5   assembly_method             denovo                                       \n",
      "6   reference_sequence                                                       \n",
      "7   datatype                    rad                                          \n",
      "8   restriction_overhang        ('TGCAG', '')                                \n",
      "9   max_low_qual_bases          5                                            \n",
      "10  phred_Qscore_offset         33                                           \n",
      "11  mindepth_statistical        6                                            \n",
      "12  mindepth_majrule            6                                            \n",
      "13  maxdepth                    10000                                        \n",
      "14  clust_threshold             0.85                                         \n",
      "15  max_barcode_mismatch        0                                            \n",
      "16  filter_adapters             0                                            \n",
      "17  filter_min_trim_len         35                                           \n",
      "18  max_alleles_consens         2                                            \n",
      "19  max_Ns_consens              (5, 5)                                       \n",
      "20  max_Hs_consens              (8, 8)                                       \n",
      "21  min_samples_locus           4                                            \n",
      "22  max_SNPs_locus              (20, 20)                                     \n",
      "23  max_Indels_locus            (8, 8)                                       \n",
      "24  max_shared_Hs_locus         0.5                                          \n",
      "25  trim_reads                  (0, 0, 0, 0)                                 \n",
      "26  trim_loci                   (0, 0, 0, 0)                                 \n",
      "27  output_formats              ['p', 's', 'v']                              \n",
      "28  pop_assign_file                                                          \n"
     ]
    }
   ],
   "source": [
    "data1.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multiple libraries and multiple lanes\n",
    "[See *ipyrad* documentation](https://ipyrad.readthedocs.io/tutorial-combining-data.html?highlight=-m%20both) for how to handle multiple libraies and lanes in this API<br>\n",
    "## barcodes_path\n",
    "Your barcodes should be set up per index group and in the same directory<Br> \n",
    "The index groups are weird, and follow this order: 06, 12 , 03, 04, 05, 07, 01, 02, <br> But the order doesn't matter as much here, as longa s your barcodes file is annotated properly.\n",
    "\n",
    "## Index by lane\n",
    "We have 1.5 libraries to run so it will look something like this: <br>\n",
    "#### multiple libraries multiple lanes<br>\n",
    "`lib1i06 = ip.Assembly(\"lib1i06\")`<br>\n",
    "`lib1i06.set_params('project_dir', './') `<br>\n",
    "`lib1i06.set_params('raw_fastq_path', './*.gz') `<br>\n",
    "`lib1i06.set_params('barcodes_path', '') `<br>\n",
    "`lib1i06.set_params('assembly_method', 'denovo+refrence')`<br>\n",
    "`lib1i06.set_params('refrence_sequence', 'Tzet_genomic.fna')`<br>\n",
    "`lib1i06.set_params('datatype', 'ddrad')`<br>\n",
    "`lib1i06.set_params('restriction_overhang', 'TGCAG, CGG') `<br>\n",
    "`lib1i06.set_params('clust_threshold', '0.9')`<br>\n",
    "`lib1i06.set_params('mindepth_statistical', '6')`<br>\n",
    "`lib1i06.set_params('mindepth_majrule', '6')`<br>\n",
    "`lib1i06.set_params('filter_adapters', '1')`<br>\n",
    "`lib1i06.set_params('max_SNPs_locus', '20, 30')`<br>\n",
    "`lib1i06.set_params('output_formats', '*')`<br>\n",
    "`lib1i06.run(\"1\")`<br>\n",
    "...<br>\n",
    "`lib1i01 = ip.Assembly(\"lib1i01\")`<br>\n",
    "`lib1i01.set_params('project_dir', './') `<br>\n",
    "`lib1i01.set_params('raw_fastq_path', './*.gz') `<br>\n",
    "`lib1i01.set_params('barcodes_path', '') `<br>\n",
    "`lib1i01.set_params('assembly_method', 'denovo+refrence')`<br>\n",
    "`lib1i01.set_params('refrence_sequence', 'Tzet_genomic.fna')`<br>\n",
    "`lib1i01.set_params('datatype', 'ddrad')`<br>\n",
    "`lib1i01.set_params('restriction_overhang', 'TGCAG, CGG') `<br>\n",
    "`lib1i01.set_params('mindepth_statistical', '6')`<br>\n",
    "`lib1i01.set_params('mindepth_majrule', '6')`<br>\n",
    "`lib1i01.set_params('filter_adapters', '1')`<br>\n",
    "`lib1i01.set_params('max_SNPs_locus', '20, 30')`<br>\n",
    "`lib2i06.set_params('output_formats', '*')`<br>\n",
    "`lib2i06.set_params('clust_threshold', '0.9')`<br>\n",
    "`lib1i01.run(\"1\")`<br>\n",
    "\n",
    "`lib2i06 = ip.Assembly(\"lib1i06\")`<br>\n",
    "`lib2i06.set_params('project_dir', './') `<br>\n",
    "`lib2i06.set_params('raw_fastq_path', './*.gz') `<br>\n",
    "`lib2i06.set_params('barcodes_path', '') `<br>\n",
    "`lib2i06.set_params('assembly_method', 'denovo+refrence')`<br>\n",
    "`lib2i06.set_params('refrence_sequence', 'Tzet_genomic.fna')`<br>\n",
    "`lib2i06.set_params('datatype', 'ddrad')`<br>\n",
    "`lib2i06.set_params('restriction_overhang', 'TGCAG, CGG') `<br>\n",
    "`lib2i06.set_params('mindepth_statistical', '6')`<br>\n",
    "`lib2i06.set_params('mindepth_majrule', '6')`<br>\n",
    "`lib2i06.set_params('filter_adapters', '1')`<br>\n",
    "`lib2i06.set_params('max_SNPs_locus', '20, 30')`<br>\n",
    "`lib2i06.set_params('output_formats', '*')`<br>\n",
    "`lib2i06.set_params('clust_threshold', '0.9')`<br>\n",
    "`lib2i06.run(\"1\")`<br>\n",
    "...<br>\n",
    "`lib2i04 = ip.Assembly(\"lib1i04\")`<br>\n",
    "`lib2i04.set_params('project_dir', './') `<br>\n",
    "`lib2i04.set_params('raw_fastq_path', './*.gz') `<br>\n",
    "`lib2i04.set_params('barcodes_path', '') `<br>\n",
    "`lib2i04.set_params('assembly_method', 'denovo+refrence')`<br>\n",
    "`lib2i04.set_params('refrence_sequence', 'Tzet_genomic.fna')`<br>\n",
    "`lib2i04.set_params('datatype', 'ddrad')`<br>\n",
    "`lib2i04.set_params('restriction_overhang', 'TGCAG, CGG') `<br>\n",
    "`lib2i04.set_params('mindepth_statistical', '6')`<br>\n",
    "`lib2i04.set_params('mindepth_majrule', '6')`<br>\n",
    "`lib2i04.set_params('filter_adapters', '1')`<br>\n",
    "`lib2i04.set_params('max_SNPs_locus', '20, 30')`<br>\n",
    "`lib2i04.set_params('output_formats', '*')`<br>\n",
    "`lib2i04.set_params('clust_threshold', '0.9')`<br> \n",
    "`lib2i04.run(\"1\")`<br>\n",
    "#### merge the demultiplexed libraries!\n",
    "`fulldata = ip.merge(\"fulldata\", [lib1i06, ..., lib1i01, lib2i06, ..., lib2i04])`<br>\n",
    "#### Run the dataset!\n",
    "`.run` operates as the CLI -s command <br>\n",
    "`fulldata.run(\"234567\")`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branch Assembly\n",
    "At this point, you have the choice to branch the assembly. which might be good for manipulating parameters. For example you may want to see which parameters provide the best coverage.<br>\n",
    "    for example, you may want to run: `fulldata.run(\"2\")` first <br>\n",
    "    then check the stats on your data with `fulldata.stats`<Br>\n",
    "    then run your dataset with further steps: `fulldata.run(\"3456\")`<br>\n",
    "###### Here we want to make sure this min_sample_locus scales. <Br>\n",
    "If we only had 2 lanes, this might be reasonable. BUT we will end up with a lot of missing data. So we want to run our min_samples_locus proportional to our dataset(IE I have 130 samples, and may want to use 50 at the low end, and 100 at the high end. That is what this step is for.<br>\n",
    "<br>\n",
    "For example, we could check the coverage by changing the min_sample_locus parameter in two seperate runs<br>\n",
    "`## create a branch for outputs with min_samples = 4 (lots of missing data)`<br>\n",
    "`min4 = fulldata.branch(\"min4\")`<br>\n",
    "`min4.set_params(\"min_samples_locus\", 4)`<br>\n",
    "`min4.run(\"7\")`<br>\n",
    "\n",
    "`## create a branch for outputs with min_samples = 13 (no missing data)`<br>\n",
    "`min13 = fulldata.branch(\"min13\")`<br>\n",
    "`min13.set_params(\"min_samples_locus\", 13)`<br>\n",
    "`min13.run(\"7\")`<br>\n",
    "\n",
    "\n",
    "### Final Stats\n",
    "we can view the final stats of each step to see which we would want to use.<br>\n",
    "`min13.stats`<br><br>\n",
    "Or we can call the stats of specific steps to see which had the most coverage.<br>\n",
    "`min4.stats_dfs.s7_samples`<br>\n",
    "`min13.stats_dfs.s7_samples`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check data quality\n",
    "From here, we can begin to quality check our data. We want to check our analysis, due to varying lenghts of reads, and randomly selecting SNP's we may not maintain the Min# of samples per locus in our output (param #21 we discussed previously). Even though we compared the coverage, we want to make sure we have N loci reported in the *ipyrad* stats. This code comes from the Allenrolfea_Analysis_pipeline linked at the start above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named seaborn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ebd368a43cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#the ustr file has N samples and 2 lines per sample check the number expected rows, and loci.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#ipyrad reported Nloci and we have Nsamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmy_ustr\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'min13.ustr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named seaborn"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "#the ustr file has N samples and 2 lines per sample check the number expected rows, and loci.\n",
    "#ipyrad reported Nloci and we have Nsamples\n",
    "my_ustr =pd.read_csv('min13.ustr')\n",
    "print(my_ustr.shape) # should equal Nsamples*2 and Nloci. ex:(Nsamples*2,Nloci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis testing... \n",
    "Hypothesis_0: We expect populations in the tropics to be patchy (*source*)<br>\n",
    "**null_0**: no population structure, there is admixture across all sites, one large population<br>\n",
    "**alt_0.0**: Isolation by distance, one large pop with sub populations<br>\n",
    "**alt1_0.1**: Isolation by environment, there are multiple populations (creeks determine geneflow, individuals in a creek are more related than individuals between creeks)<br><br>\n",
    "\n",
    "Hypothesis_1: We are uncertain about the taxonomy of the published T.zeteki genome <br>\n",
    "**null_1.0**: The published T.zeteki genome is T. zeteki<br>\n",
    "**alt_1.0**: The published T.zeteki genome is likely a different species<br><br>\n",
    "    Test this hypothesis by building a phylogeny with the 6 random T.fov and 5 T.zet a insilico digested published T.zet genome<br>\n",
    "        THIS COULD HAVE AN INTERESTING COALESCENT STORY HERE, WE KNOW THAT PANAMA FORMED ~15-8MYA <br>\n",
    "        WHAT CONSEQUENCES DOES THAT HAVE FOR THESE SIBILING SPECIES!?<br><br>\n",
    "Hypothesis2: Parasitoid wasps have some selective pressure on their hosts (*source*)<br> \n",
    "**nul2**: ... something about selective pressures of parasitoid wasps?\n",
    "<br><br>\n",
    "***there is another hypothesis to test, think about it some more***\n",
    "<br><br>\n",
    "## find interesting loci, and do a literature search to see if we know the function of them yet!\n",
    "we can use HWE... in poppr, we can extract a list of loci we know is not in HWE and explore that dataset... somehow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAxML tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tetrad-- quartet tree inference\n",
    "much like SVDquartets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *structure* analysis\n",
    "[see ipyrad documentation](https://nbviewer.jupyter.org/github/dereneaton/ipyrad/blob/master/tests/cookbook-structure-pedicularis.ipynb)\n",
    "#### input and output file locations\n",
    "#### create *structure* class object\n",
    "#### set parameters for *structure* object\n",
    "#### submit job on the cluster\n",
    "#### summarize replicates with clump\n",
    "#### calculate the best K and test for convergence\n",
    "#### create structure plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See { notebook name } for further R analysis!\n",
    "1. test genetic distance by geographic distance\n",
    "2. map samples (see.... ???)\n",
    "3. check HWE (poppr & adagenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map Samples\n",
    "May use Python, but we have a pretty straightforward way of doing this in R right now. This will be based off clusters/k values, if any, and mapping those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore admixture\n",
    "using TREEMIX & ABBA-BABA admixture inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coalescent analysis?\n",
    "... biogeogrphy here though..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
